#!/bin/bash

#SBATCH --partition=debug
#SBATCH --ntasks=2
#SBATCH --cpus-per-task=8
#SBATCH --mem-per-cpu=3500
#SBATCH --time=60:00
#SBATCH --output=outfile-%J
 
. setenv-gpu.sh

echo "CONCURRENTGPU $CONCURRENTGPU"
echo "SLURM_NTASKS $SLURM_NTASKS"
echo "NUM_EXECUTOR_CORES $NUM_EXECUTOR_CORES"
echo "RESOURCE_GPU_AMT $RESOURCE_GPU_AMT"

mkdir -p $SPARK_CONF_DIR
mkdir -p $MOUNT/sparkRapidsPlugin
mkdir -p $MOUNT/parquet
mkdir -p $MOUNT/results

if [ ! -d "$SPARK_HOME/sbin" ]
then
    wget -c ${SPARK_URL} -O - | sudo tar --strip-components=1 --one-top-level=${SPARK_HOME} -xz
else
    echo "${SPARK_HOME} exists"
fi

sudo chown -R $(id -u):$(id -g) ${MOUNT}/spark

if [ ! -f "${MOUNT}/sparkRapidsPlugin/getGpusResources.sh" ]
then
    wget -P ${MOUNT}/sparkRapidsPlugin -c ${GET_CPU_RES_URL} && chmod +x ${MOUNT}/sparkRapidsPlugin/getGpusResources.sh
else
    echo "getGpusResources.sh exists"
fi

if [ ! -f "${MOUNT}/sparkRapidsPlugin/${CUDF_JAR_NAME}" ]
then
    wget -P ${MOUNT}/sparkRapidsPlugin -c ${CUDF_FILES_URL}
else
    echo "${CUDF_JAR_NAME} exists"
fi

if [ ! -f "${MOUNT}/sparkRapidsPlugin/${RAPIDS_JAR_NAME}" ]
then
    wget -P ${MOUNT}/sparkRapidsPlugin -c ${RAPIDS_PLUGIN_URL}
else
    echo "${RAPIDS_JAR_NAME} exists"
fi

if [ ! -d "$MOUNT/parquet/customer" ]
then
    wget -c ${PARQUET_UR} -O - | sudo tar --strip-components=1 --one-top-level=${MOUNT}/parquet -xz
    
else
    echo "${MOUNT}/parquet/customer exists"
fi

$SPARK_HOME/sbin/start-all.sh
. wait-worker.sh

mkdir -p $MOUNT/parquet
mkdir -p $MOUNT/results

QUERY_SPECIAL_PARAMS=""
if [ $QUERY == "Q24" ];then
        QUERY_SPECIAL_PARAMS="--conf spark.rapids.sql.hasNans=false"
fi
if [ $QUERY == "Q12" ];then
        QUERY_SPECIAL_PARAMS="--conf spark.rapids.sql.batchSizeBytes=512mb --conf spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version=2"
fi

$SPARK_HOME/bin/spark-submit $CMDPARAMS \
        --class ai.rapids.spark.examples.tpcxbb.Main \
        --conf spark.rapids.sql.variableFloatAgg.enabled=true \
        --conf spark.plugins=com.nvidia.spark.SQLPlugin \
        --conf spark.rapids.sql.concurrentGpuTasks=$CONCURRENTGPU \
        --conf spark.rapids.memory.gpu.pooling.enabled=true \
        --conf spark.rapids.memory.pinnedPool.size=8g \
        --conf spark.rapids.sql.incompatibleOps.enabled=true \
        --conf spark.executor.extraJavaOptions='-Dai.rapids.cudf.nvtx.enabled=true -Dai.rapids.cudf.prefer-pinned=true -Dai.rapids.spark.semaphore.enabled=true' \
        --conf spark.rapids.sql.explain=ALL \
        --conf spark.executor.resource.gpu.amount=1 \
        --conf spark.task.resource.gpu.amount=$RESOURCE_GPU_AMT \
        --conf spark.rapids.sql.batchSizeByte=512M \
        --conf spark.sql.parquet.read.allocation.size=64M \
        --conf spark.sql.parquet.outputTimestampType=TIMESTAMP_MICROS \
        $UCX_PARAMS \
        $QUERY_SPECIAL_PARAMS \
        bbsql_apps-0.2.2-SNAPSHOT.jar --xpu=GPU \
        --query="$QUERY" \
        --input="$INPUT_PATH" \
        --output="${OUTPUT_PATH}-gpu/$QUERY"

#sleep infinity
$SPARK_HOME/sbin/stop-all.sh
